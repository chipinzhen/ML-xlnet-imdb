{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d91a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8e7ad44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: matplotlib in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.16 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from matplotlib) (3.0.3)\n",
      "Requirement already satisfied: six>=1.5 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.12.0-py3-none-any.whl (3.1 MB)\n",
      "Requirement already satisfied: sacremoses in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: numpy>=1.17 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from transformers) (2021.10.23)\n",
      "Requirement already satisfied: requests in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Collecting huggingface-hub>=0.0.17\n",
      "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.3.2-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.3)\n",
      "Requirement already satisfied: colorama in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: six in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Installing collected packages: filelock, tokenizers, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.3.2 huggingface-hub-0.0.19 tokenizers-0.10.3 transformers-4.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "!pip install transformers\n",
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56e3024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-7.6.5-py2.py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipywidgets) (6.4.2)\n",
      "Collecting widgetsnbextension~=3.5.0\n",
      "  Downloading widgetsnbextension-3.5.2-py2.py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.0.2-py3-none-any.whl (243 kB)\n",
      "Requirement already satisfied: ipython>=4.0.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipywidgets) (7.28.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: pickleshare in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.21)\n",
      "Requirement already satisfied: colorama in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: jedi>=0.16 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: backcall in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (58.0.4)\n",
      "Requirement already satisfied: pygments in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: decorator in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: pyzmq>=13 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: pywin32>=1.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (302)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.1.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: wcwidth in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.5)\n",
      "Requirement already satisfied: prometheus-client in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.11.0)\n",
      "Requirement already satisfied: jinja2 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.2)\n",
      "Requirement already satisfied: nbconvert in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.2.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: argon2-cffi in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.1.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.5)\n",
      "Requirement already satisfied: cffi>=1.0.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pycparser in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: bleach in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: testpath in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: defusedxml in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.4)\n",
      "Requirement already satisfied: webencodings in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in g:\\anaconda3\\envs\\xlnet\\lib\\site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.3)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-7.6.5 jupyterlab-widgets-1.0.2 widgetsnbextension-3.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fccfe745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
    "from transformers import AdamW\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "912b5570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1080'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f8d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./IMDB Dataset.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb8b1b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49999, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38a2d677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc001ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df.review.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98d8ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence + \" [SEP] [CLS]\" for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc17380",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.sentiment.values\n",
    "labels = [1 if label == 'positive' else 0 for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "929bcf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f7b9d6fbb6493ca813f8775c254567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73baf8aeb8a460eb7ab4958f3ba0716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102fee21e28042b2974898fe9c364d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da511e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [tokenizer.tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec2e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁one', '▁of', '▁the', '▁other', '▁reviewer', 's', '▁has', '▁mentioned', '▁that', '▁after', '▁watching', '▁just', '▁1', '▁', 'oz', '▁episode', '▁you', \"'\", 'll', '▁be', '▁hooked', '.', '▁they', '▁are', '▁right', ',', '▁as', '▁this', '▁is', '▁exactly', '▁what', '▁happened', '▁with', '▁me', '.', '<', 'br', '▁', '/', '>', '<', 'br', '▁', '/', '>', 'the', '▁first', '▁thing', '▁that', '▁struck', '▁me', '▁about', '▁', 'oz', '▁was', '▁its', '▁brutality', '▁and', '▁un', 'fli', 'nch', 'ing', '▁scenes', '▁of', '▁violence', ',', '▁which', '▁set', '▁in', '▁right', '▁from', '▁the', '▁word', '▁go', '.', '▁trust', '▁me', ',', '▁this', '▁is', '▁not', '▁a', '▁show', '▁for', '▁the', '▁faint', '▁', 'hearted', '▁or', '▁timid', '.', '▁this', '▁show', '▁pulls', '▁no', '▁punches', '▁with', '▁regards', '▁to', '▁drugs', ',', '▁sex', '▁or', '▁violence', '.', '▁its', '▁is', '▁hardcore', ',', '▁in', '▁the', '▁classic', '▁use', '▁of', '▁the', '▁word', '.', '<', 'br', '▁', '/', '>', '<', 'br', '▁', '/', '>', 'it', '▁is', '▁called', '▁', 'oz', '▁as', '▁that', '▁is', '▁the', '▁nickname', '▁given', '▁to', '▁the', '▁', 'os', 'wald', '▁maximum', '▁security', '▁state', '▁pen', 'it', 'ent', 'ary', '.', '▁it', '▁focuses', '▁mainly', '▁on', '▁emerald', '▁city', ',', '▁an', '▁experimental', '▁section', '▁of', '▁the', '▁prison', '▁where', '▁all', '▁the', '▁cells', '▁have', '▁glass', '▁front', 's', '▁and', '▁face', '▁in', 'wards', ',', '▁so', '▁privacy', '▁is', '▁not', '▁high', '▁on', '▁the', '▁agenda', '.', '▁em', '▁city', '▁is', '▁home', '▁to', '▁many', '.', '.', 'ary', 'ans', ',', '▁', 'mus', 'lim', 's', ',', '▁gangs', 'tas', ',', '▁', 'latin', 'os', ',', '▁christian', 's', ',', '▁it', 'al', 'ians', ',', '▁', 'ir', 'ish', '▁and', '▁more', '.', '.', '.', '.', 'so', '▁scuffle', 's', ',', '▁death', '▁stare', 's', ',', '▁do', 'd', 'gy', '▁dealings', '▁and', '▁shady', '▁agreements', '▁are', '▁never', '▁far', '▁away', '.', '<', 'br', '▁', '/', '>', '<', 'br', '▁', '/', '>', 'i', '▁would', '▁say', '▁the', '▁main', '▁appeal', '▁of', '▁the', '▁show', '▁is', '▁due', '▁to', '▁the', '▁fact', '▁that', '▁it', '▁goes', '▁where', '▁other', '▁shows', '▁wouldn', \"'\", 't', '▁dare', '.', '▁forget', '▁pretty', '▁pictures', '▁painted', '▁for', '▁mainstream', '▁audiences', ',', '▁forget', '▁charm', ',', '▁forget', '▁romance', '.', '.', '.', 'oz', '▁doesn', \"'\", 't', '▁mess', '▁around', '.', '▁the', '▁first', '▁episode', '▁', 'i', '▁ever', '▁saw', '▁struck', '▁me', '▁as', '▁so', '▁nasty', '▁it', '▁was', '▁surreal', ',', '▁', 'i', '▁couldn', \"'\", 't', '▁say', '▁', 'i', '▁was', '▁ready', '▁for', '▁it', ',', '▁but', '▁as', '▁', 'i', '▁watched', '▁more', ',', '▁', 'i', '▁developed', '▁a', '▁taste', '▁for', '▁', 'oz', ',', '▁and', '▁got', '▁accustomed', '▁to', '▁the', '▁high', '▁levels', '▁of', '▁graphic', '▁violence', '.', '▁not', '▁just', '▁violence', ',', '▁but', '▁injustice', '▁', '(', 'cro', 'ok', 'ed', '▁guards', '▁who', \"'\", 'll', '▁be', '▁sold', '▁out', '▁for', '▁a', '▁nickel', ',', '▁inmates', '▁who', \"'\", 'll', '▁kill', '▁on', '▁order', '▁and', '▁get', '▁away', '▁with', '▁it', ',', '▁well', '▁manner', 'ed', ',', '▁middle', '▁class', '▁inmates', '▁being', '▁turned', '▁into', '▁prison', '▁bitch', 'es', '▁due', '▁to', '▁their', '▁lack', '▁of', '▁street', '▁skills', '▁or', '▁prison', '▁experience', ')', '▁watching', '▁', 'oz', ',', '▁you', '▁may', '▁become', '▁comfortable', '▁with', '▁what', '▁is', '▁uncomfortable', '▁viewing', '.', '.', '.', '.', 'that', 's', '▁if', '▁you', '▁can', '▁get', '▁in', '▁touch', '▁with', '▁your', '▁darker', '▁side', '.', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']']\n"
     ]
    }
   ],
   "source": [
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e870e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f68dc31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7251e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7491249c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  65,   20,   18, ...,  167, 3151,  669],\n",
       "       [  24, 3239,  293, ..., 1062,   21, 2062],\n",
       "       [  17,  150,  449, ...,   65,   20, 3302],\n",
       "       ...,\n",
       "       [  17,  150,  569, ...,   27,  116, 5182],\n",
       "       [  17,  150,   26, ...,   19,   33,  106],\n",
       "       [ 116,   65, 5883, ...,   74,  248,   52]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d351bf5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7f1fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=1029, test_size=0.2)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=1029, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc0c1335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data set into training, validation and test set\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84912d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da74569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e48d7f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb699b7aa864d879ee46cdeeac6e89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0cae6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLNetForSequenceClassification(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sequence_summary): SequenceSummary(\n",
       "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (first_dropout): Identity()\n",
       "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4598eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9160d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This variable contains all of the hyperparemeter information and the learning rate.\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caf3c350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|███████████████████████████████████████                                                                                                                     | 1/4 [22:38<1:07:55, 1358.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.31759870747576935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|███████████████████████████████████████████████████████████████████████████████                                                                               | 2/4 [45:23<45:24, 1362.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.220070587658172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                       | 3/4 [1:07:43<22:32, 1352.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.15134536687863875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [1:29:58<00:00, 1349.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10762934819170332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_set = []\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "    model.train()\n",
    "  \n",
    "  # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "    # Train the data for one epoch\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        train_loss_set.append(loss.item())    \n",
    "\n",
    "        loss.backward()\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcac0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './xlnet_model_1029.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70762fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, batch in enumerate(validation_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        # print (outputs)\n",
    "        prediction = torch.argmax(outputs[0],dim=1)\n",
    "        total += b_labels.size(0)\n",
    "        correct+=(prediction==b_labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06449d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on vla data is: 89.2 %\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy of the model on vla data is: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383dbdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xlnet]",
   "language": "python",
   "name": "conda-env-xlnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
